{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-mmdetection.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XERPLVn0vDi"
      },
      "source": [
        "# Colab-mmdetection\n",
        "\n",
        "Original repo: [open-mmlab/mmdetection](https://github.com/open-mmlab/mmdetection)\n",
        "\n",
        "Also thanks to this [issue](https://github.com/open-mmlab/mmdetection/issues/3305)\n",
        "\n",
        "My fork: [styler00dollar/Colab-mmdetection](https://github.com/styler00dollar/Colab-mmdetection)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADCrJ9ZXt3yH"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-X3nDDMppBw",
        "cellView": "form"
      },
      "source": [
        "#@title install\n",
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\n",
        "!pip install torch==1.8.0+cu111 torchvision==0.9.0+cu111 torchaudio==0.8.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "\n",
        "# install mmcv-full thus we could use CUDA operators\n",
        "#!pip install mmcv-full\n",
        "!pip install mmcv-full==1.3.8 -f https://download.openmmlab.com/mmcv/dist/cu111/torch1.8.0/index.html\n",
        "\n",
        "# Install mmdetection\n",
        "!rm -rf mmdetection\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\n",
        "%cd mmdetection\n",
        "\n",
        "!pip install -e .\n",
        "\n",
        "# install Pillow 7.0.0 back in order to avoid bug in colab\n",
        "!pip install Pillow==7.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw3gJtwx2-x8"
      },
      "source": [
        "# Train\n",
        "Example usage with ```mask_rcnn_r50_fpn_2x_coco.py```. For a coco dataset it is needed to change the amount of classes inside the ```coco.py``` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PBA4OIhyo1Na",
        "cellView": "form"
      },
      "source": [
        "#@title coco.py (config classes)\n",
        "%%writefile /content/mmdetection/mmdet/datasets/coco.py\n",
        "import itertools\n",
        "import logging\n",
        "import os.path as osp\n",
        "import tempfile\n",
        "from collections import OrderedDict\n",
        "\n",
        "import mmcv\n",
        "import numpy as np\n",
        "from mmcv.utils import print_log\n",
        "from pycocotools.coco import COCO\n",
        "from pycocotools.cocoeval import COCOeval\n",
        "from terminaltables import AsciiTable\n",
        "\n",
        "from mmdet.core import eval_recalls\n",
        "from .builder import DATASETS\n",
        "from .custom import CustomDataset\n",
        "\n",
        "try:\n",
        "    import pycocotools\n",
        "    if not hasattr(pycocotools, '__sphinx_mock__'):  # for doc generation\n",
        "        assert pycocotools.__version__ >= '12.0.2'\n",
        "except AssertionError:\n",
        "    raise AssertionError('Incompatible version of pycocotools is installed. '\n",
        "                         'Run pip uninstall pycocotools first. Then run pip '\n",
        "                         'install mmpycocotools to install open-mmlab forked '\n",
        "                         'pycocotools.')\n",
        "\n",
        "\n",
        "@DATASETS.register_module()\n",
        "class CocoDataset(CustomDataset):\n",
        "    \"\"\"\n",
        "    CLASSES = ('person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\n",
        "               'train', 'truck', 'boat', 'traffic light', 'fire hydrant',\n",
        "               'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',\n",
        "               'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',\n",
        "               'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\n",
        "               'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',\n",
        "               'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\n",
        "               'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\n",
        "               'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',\n",
        "               'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\n",
        "               'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',\n",
        "               'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\n",
        "               'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock',\n",
        "               'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush')\n",
        "    \"\"\"\n",
        "    CLASSES = ('Arduino', 'ESP8266', 'Heltec', 'Raspberry')\n",
        "\n",
        "    def load_annotations(self, ann_file):\n",
        "        \"\"\"Load annotation from COCO style annotation file.\n",
        "\n",
        "        Args:\n",
        "            ann_file (str): Path of annotation file.\n",
        "\n",
        "        Returns:\n",
        "            list[dict]: Annotation info from COCO api.\n",
        "        \"\"\"\n",
        "\n",
        "        self.coco = COCO(ann_file)\n",
        "        self.cat_ids = self.coco.get_cat_ids(cat_names=self.CLASSES)\n",
        "        self.cat2label = {cat_id: i for i, cat_id in enumerate(self.cat_ids)}\n",
        "        self.img_ids = self.coco.get_img_ids()\n",
        "        data_infos = []\n",
        "        for i in self.img_ids:\n",
        "            info = self.coco.load_imgs([i])[0]\n",
        "            info['filename'] = info['file_name']\n",
        "            data_infos.append(info)\n",
        "        return data_infos\n",
        "\n",
        "    def get_ann_info(self, idx):\n",
        "        \"\"\"Get COCO annotation by index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of data.\n",
        "\n",
        "        Returns:\n",
        "            dict: Annotation info of specified index.\n",
        "        \"\"\"\n",
        "\n",
        "        img_id = self.data_infos[idx]['id']\n",
        "        ann_ids = self.coco.get_ann_ids(img_ids=[img_id])\n",
        "        ann_info = self.coco.load_anns(ann_ids)\n",
        "        return self._parse_ann_info(self.data_infos[idx], ann_info)\n",
        "\n",
        "    def get_cat_ids(self, idx):\n",
        "        \"\"\"Get COCO category ids by index.\n",
        "\n",
        "        Args:\n",
        "            idx (int): Index of data.\n",
        "\n",
        "        Returns:\n",
        "            list[int]: All categories in the image of specified index.\n",
        "        \"\"\"\n",
        "\n",
        "        img_id = self.data_infos[idx]['id']\n",
        "        ann_ids = self.coco.get_ann_ids(img_ids=[img_id])\n",
        "        ann_info = self.coco.load_anns(ann_ids)\n",
        "        return [ann['category_id'] for ann in ann_info]\n",
        "\n",
        "    def _filter_imgs(self, min_size=32):\n",
        "        \"\"\"Filter images too small or without ground truths.\"\"\"\n",
        "        valid_inds = []\n",
        "        # obtain images that contain annotation\n",
        "        ids_with_ann = set(_['image_id'] for _ in self.coco.anns.values())\n",
        "        # obtain images that contain annotations of the required categories\n",
        "        ids_in_cat = set()\n",
        "        for i, class_id in enumerate(self.cat_ids):\n",
        "            ids_in_cat |= set(self.coco.cat_img_map[class_id])\n",
        "        # merge the image id sets of the two conditions and use the merged set\n",
        "        # to filter out images if self.filter_empty_gt=True\n",
        "        ids_in_cat &= ids_with_ann\n",
        "\n",
        "        valid_img_ids = []\n",
        "        for i, img_info in enumerate(self.data_infos):\n",
        "            img_id = self.img_ids[i]\n",
        "            if self.filter_empty_gt and img_id not in ids_in_cat:\n",
        "                continue\n",
        "            if min(img_info['width'], img_info['height']) >= min_size:\n",
        "                valid_inds.append(i)\n",
        "                valid_img_ids.append(img_id)\n",
        "        self.img_ids = valid_img_ids\n",
        "        return valid_inds\n",
        "\n",
        "    def _parse_ann_info(self, img_info, ann_info):\n",
        "        \"\"\"Parse bbox and mask annotation.\n",
        "\n",
        "        Args:\n",
        "            ann_info (list[dict]): Annotation info of an image.\n",
        "            with_mask (bool): Whether to parse mask annotations.\n",
        "\n",
        "        Returns:\n",
        "            dict: A dict containing the following keys: bboxes, bboxes_ignore,\\\n",
        "                labels, masks, seg_map. \"masks\" are raw annotations and not \\\n",
        "                decoded into binary masks.\n",
        "        \"\"\"\n",
        "        gt_bboxes = []\n",
        "        gt_labels = []\n",
        "        gt_bboxes_ignore = []\n",
        "        gt_masks_ann = []\n",
        "        for i, ann in enumerate(ann_info):\n",
        "            if ann.get('ignore', False):\n",
        "                continue\n",
        "            x1, y1, w, h = ann['bbox']\n",
        "            inter_w = max(0, min(x1 + w, img_info['width']) - max(x1, 0))\n",
        "            inter_h = max(0, min(y1 + h, img_info['height']) - max(y1, 0))\n",
        "            if inter_w * inter_h == 0:\n",
        "                continue\n",
        "            if ann['area'] <= 0 or w < 1 or h < 1:\n",
        "                continue\n",
        "            if ann['category_id'] not in self.cat_ids:\n",
        "                continue\n",
        "            bbox = [x1, y1, x1 + w, y1 + h]\n",
        "            if ann.get('iscrowd', False):\n",
        "                gt_bboxes_ignore.append(bbox)\n",
        "            else:\n",
        "                gt_bboxes.append(bbox)\n",
        "                gt_labels.append(self.cat2label[ann['category_id']])\n",
        "                gt_masks_ann.append(ann.get('segmentation', None))\n",
        "\n",
        "        if gt_bboxes:\n",
        "            gt_bboxes = np.array(gt_bboxes, dtype=np.float32)\n",
        "            gt_labels = np.array(gt_labels, dtype=np.int64)\n",
        "        else:\n",
        "            gt_bboxes = np.zeros((0, 4), dtype=np.float32)\n",
        "            gt_labels = np.array([], dtype=np.int64)\n",
        "\n",
        "        if gt_bboxes_ignore:\n",
        "            gt_bboxes_ignore = np.array(gt_bboxes_ignore, dtype=np.float32)\n",
        "        else:\n",
        "            gt_bboxes_ignore = np.zeros((0, 4), dtype=np.float32)\n",
        "\n",
        "        seg_map = img_info['filename'].replace('jpg', 'png')\n",
        "\n",
        "        ann = dict(\n",
        "            bboxes=gt_bboxes,\n",
        "            labels=gt_labels,\n",
        "            bboxes_ignore=gt_bboxes_ignore,\n",
        "            masks=gt_masks_ann,\n",
        "            seg_map=seg_map)\n",
        "\n",
        "        return ann\n",
        "\n",
        "    def xyxy2xywh(self, bbox):\n",
        "        \"\"\"Convert ``xyxy`` style bounding boxes to ``xywh`` style for COCO\n",
        "        evaluation.\n",
        "\n",
        "        Args:\n",
        "            bbox (numpy.ndarray): The bounding boxes, shape (4, ), in\n",
        "                ``xyxy`` order.\n",
        "\n",
        "        Returns:\n",
        "            list[float]: The converted bounding boxes, in ``xywh`` order.\n",
        "        \"\"\"\n",
        "\n",
        "        _bbox = bbox.tolist()\n",
        "        return [\n",
        "            _bbox[0],\n",
        "            _bbox[1],\n",
        "            _bbox[2] - _bbox[0],\n",
        "            _bbox[3] - _bbox[1],\n",
        "        ]\n",
        "\n",
        "    def _proposal2json(self, results):\n",
        "        \"\"\"Convert proposal results to COCO json style.\"\"\"\n",
        "        json_results = []\n",
        "        for idx in range(len(self)):\n",
        "            img_id = self.img_ids[idx]\n",
        "            bboxes = results[idx]\n",
        "            for i in range(bboxes.shape[0]):\n",
        "                data = dict()\n",
        "                data['image_id'] = img_id\n",
        "                data['bbox'] = self.xyxy2xywh(bboxes[i])\n",
        "                data['score'] = float(bboxes[i][4])\n",
        "                data['category_id'] = 1\n",
        "                json_results.append(data)\n",
        "        return json_results\n",
        "\n",
        "    def _det2json(self, results):\n",
        "        \"\"\"Convert detection results to COCO json style.\"\"\"\n",
        "        json_results = []\n",
        "        for idx in range(len(self)):\n",
        "            img_id = self.img_ids[idx]\n",
        "            result = results[idx]\n",
        "            for label in range(len(result)):\n",
        "                bboxes = result[label]\n",
        "                for i in range(bboxes.shape[0]):\n",
        "                    data = dict()\n",
        "                    data['image_id'] = img_id\n",
        "                    data['bbox'] = self.xyxy2xywh(bboxes[i])\n",
        "                    data['score'] = float(bboxes[i][4])\n",
        "                    data['category_id'] = self.cat_ids[label]\n",
        "                    json_results.append(data)\n",
        "        return json_results\n",
        "\n",
        "    def _segm2json(self, results):\n",
        "        \"\"\"Convert instance segmentation results to COCO json style.\"\"\"\n",
        "        bbox_json_results = []\n",
        "        segm_json_results = []\n",
        "        for idx in range(len(self)):\n",
        "            img_id = self.img_ids[idx]\n",
        "            det, seg = results[idx]\n",
        "            for label in range(len(det)):\n",
        "                # bbox results\n",
        "                bboxes = det[label]\n",
        "                for i in range(bboxes.shape[0]):\n",
        "                    data = dict()\n",
        "                    data['image_id'] = img_id\n",
        "                    data['bbox'] = self.xyxy2xywh(bboxes[i])\n",
        "                    data['score'] = float(bboxes[i][4])\n",
        "                    data['category_id'] = self.cat_ids[label]\n",
        "                    bbox_json_results.append(data)\n",
        "\n",
        "                # segm results\n",
        "                # some detectors use different scores for bbox and mask\n",
        "                if isinstance(seg, tuple):\n",
        "                    segms = seg[0][label]\n",
        "                    mask_score = seg[1][label]\n",
        "                else:\n",
        "                    segms = seg[label]\n",
        "                    mask_score = [bbox[4] for bbox in bboxes]\n",
        "                for i in range(bboxes.shape[0]):\n",
        "                    data = dict()\n",
        "                    data['image_id'] = img_id\n",
        "                    data['bbox'] = self.xyxy2xywh(bboxes[i])\n",
        "                    data['score'] = float(mask_score[i])\n",
        "                    data['category_id'] = self.cat_ids[label]\n",
        "                    if isinstance(segms[i]['counts'], bytes):\n",
        "                        segms[i]['counts'] = segms[i]['counts'].decode()\n",
        "                    data['segmentation'] = segms[i]\n",
        "                    segm_json_results.append(data)\n",
        "        return bbox_json_results, segm_json_results\n",
        "\n",
        "    def results2json(self, results, outfile_prefix):\n",
        "        \"\"\"Dump the detection results to a COCO style json file.\n",
        "\n",
        "        There are 3 types of results: proposals, bbox predictions, mask\n",
        "        predictions, and they have different data types. This method will\n",
        "        automatically recognize the type, and dump them to json files.\n",
        "\n",
        "        Args:\n",
        "            results (list[list | tuple | ndarray]): Testing results of the\n",
        "                dataset.\n",
        "            outfile_prefix (str): The filename prefix of the json files. If the\n",
        "                prefix is \"somepath/xxx\", the json files will be named\n",
        "                \"somepath/xxx.bbox.json\", \"somepath/xxx.segm.json\",\n",
        "                \"somepath/xxx.proposal.json\".\n",
        "\n",
        "        Returns:\n",
        "            dict[str: str]: Possible keys are \"bbox\", \"segm\", \"proposal\", and \\\n",
        "                values are corresponding filenames.\n",
        "        \"\"\"\n",
        "        result_files = dict()\n",
        "        if isinstance(results[0], list):\n",
        "            json_results = self._det2json(results)\n",
        "            result_files['bbox'] = f'{outfile_prefix}.bbox.json'\n",
        "            result_files['proposal'] = f'{outfile_prefix}.bbox.json'\n",
        "            mmcv.dump(json_results, result_files['bbox'])\n",
        "        elif isinstance(results[0], tuple):\n",
        "            json_results = self._segm2json(results)\n",
        "            result_files['bbox'] = f'{outfile_prefix}.bbox.json'\n",
        "            result_files['proposal'] = f'{outfile_prefix}.bbox.json'\n",
        "            result_files['segm'] = f'{outfile_prefix}.segm.json'\n",
        "            mmcv.dump(json_results[0], result_files['bbox'])\n",
        "            mmcv.dump(json_results[1], result_files['segm'])\n",
        "        elif isinstance(results[0], np.ndarray):\n",
        "            json_results = self._proposal2json(results)\n",
        "            result_files['proposal'] = f'{outfile_prefix}.proposal.json'\n",
        "            mmcv.dump(json_results, result_files['proposal'])\n",
        "        else:\n",
        "            raise TypeError('invalid type of results')\n",
        "        return result_files\n",
        "\n",
        "    def fast_eval_recall(self, results, proposal_nums, iou_thrs, logger=None):\n",
        "        gt_bboxes = []\n",
        "        for i in range(len(self.img_ids)):\n",
        "            ann_ids = self.coco.get_ann_ids(img_ids=self.img_ids[i])\n",
        "            ann_info = self.coco.load_anns(ann_ids)\n",
        "            if len(ann_info) == 0:\n",
        "                gt_bboxes.append(np.zeros((0, 4)))\n",
        "                continue\n",
        "            bboxes = []\n",
        "            for ann in ann_info:\n",
        "                if ann.get('ignore', False) or ann['iscrowd']:\n",
        "                    continue\n",
        "                x1, y1, w, h = ann['bbox']\n",
        "                bboxes.append([x1, y1, x1 + w, y1 + h])\n",
        "            bboxes = np.array(bboxes, dtype=np.float32)\n",
        "            if bboxes.shape[0] == 0:\n",
        "                bboxes = np.zeros((0, 4))\n",
        "            gt_bboxes.append(bboxes)\n",
        "\n",
        "        recalls = eval_recalls(\n",
        "            gt_bboxes, results, proposal_nums, iou_thrs, logger=logger)\n",
        "        ar = recalls.mean(axis=1)\n",
        "        return ar\n",
        "\n",
        "    def format_results(self, results, jsonfile_prefix=None, **kwargs):\n",
        "        \"\"\"Format the results to json (standard format for COCO evaluation).\n",
        "\n",
        "        Args:\n",
        "            results (list[tuple | numpy.ndarray]): Testing results of the\n",
        "                dataset.\n",
        "            jsonfile_prefix (str | None): The prefix of json files. It includes\n",
        "                the file path and the prefix of filename, e.g., \"a/b/prefix\".\n",
        "                If not specified, a temp file will be created. Default: None.\n",
        "\n",
        "        Returns:\n",
        "            tuple: (result_files, tmp_dir), result_files is a dict containing \\\n",
        "                the json filepaths, tmp_dir is the temporal directory created \\\n",
        "                for saving json files when jsonfile_prefix is not specified.\n",
        "        \"\"\"\n",
        "        assert isinstance(results, list), 'results must be a list'\n",
        "        assert len(results) == len(self), (\n",
        "            'The length of results is not equal to the dataset len: {} != {}'.\n",
        "            format(len(results), len(self)))\n",
        "\n",
        "        if jsonfile_prefix is None:\n",
        "            tmp_dir = tempfile.TemporaryDirectory()\n",
        "            jsonfile_prefix = osp.join(tmp_dir.name, 'results')\n",
        "        else:\n",
        "            tmp_dir = None\n",
        "        result_files = self.results2json(results, jsonfile_prefix)\n",
        "        return result_files, tmp_dir\n",
        "\n",
        "    def evaluate(self,\n",
        "                 results,\n",
        "                 metric='bbox',\n",
        "                 logger=None,\n",
        "                 jsonfile_prefix=None,\n",
        "                 classwise=False,\n",
        "                 proposal_nums=(100, 300, 1000),\n",
        "                 iou_thrs=None,\n",
        "                 metric_items=None):\n",
        "        \"\"\"Evaluation in COCO protocol.\n",
        "\n",
        "        Args:\n",
        "            results (list[list | tuple]): Testing results of the dataset.\n",
        "            metric (str | list[str]): Metrics to be evaluated. Options are\n",
        "                'bbox', 'segm', 'proposal', 'proposal_fast'.\n",
        "            logger (logging.Logger | str | None): Logger used for printing\n",
        "                related information during evaluation. Default: None.\n",
        "            jsonfile_prefix (str | None): The prefix of json files. It includes\n",
        "                the file path and the prefix of filename, e.g., \"a/b/prefix\".\n",
        "                If not specified, a temp file will be created. Default: None.\n",
        "            classwise (bool): Whether to evaluating the AP for each class.\n",
        "            proposal_nums (Sequence[int]): Proposal number used for evaluating\n",
        "                recalls, such as recall@100, recall@1000.\n",
        "                Default: (100, 300, 1000).\n",
        "            iou_thrs (Sequence[float], optional): IoU threshold used for\n",
        "                evaluating recalls/mAPs. If set to a list, the average of all\n",
        "                IoUs will also be computed. If not specified, [0.50, 0.55,\n",
        "                0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95] will be used.\n",
        "                Default: None.\n",
        "            metric_items (list[str] | str, optional): Metric items that will\n",
        "                be returned. If not specified, ``['AR@100', 'AR@300',\n",
        "                'AR@1000', 'AR_s@1000', 'AR_m@1000', 'AR_l@1000' ]`` will be\n",
        "                used when ``metric=='proposal'``, ``['mAP', 'mAP_50', 'mAP_75',\n",
        "                'mAP_s', 'mAP_m', 'mAP_l']`` will be used when\n",
        "                ``metric=='bbox' or metric=='segm'``.\n",
        "\n",
        "        Returns:\n",
        "            dict[str, float]: COCO style evaluation metric.\n",
        "        \"\"\"\n",
        "\n",
        "        metrics = metric if isinstance(metric, list) else [metric]\n",
        "        allowed_metrics = ['bbox', 'segm', 'proposal', 'proposal_fast']\n",
        "        for metric in metrics:\n",
        "            if metric not in allowed_metrics:\n",
        "                raise KeyError(f'metric {metric} is not supported')\n",
        "        if iou_thrs is None:\n",
        "            iou_thrs = np.linspace(\n",
        "                .5, 0.95, int(np.round((0.95 - .5) / .05)) + 1, endpoint=True)\n",
        "        if metric_items is not None:\n",
        "            if not isinstance(metric_items, list):\n",
        "                metric_items = [metric_items]\n",
        "\n",
        "        result_files, tmp_dir = self.format_results(results, jsonfile_prefix)\n",
        "\n",
        "        eval_results = OrderedDict()\n",
        "        cocoGt = self.coco\n",
        "        for metric in metrics:\n",
        "            msg = f'Evaluating {metric}...'\n",
        "            if logger is None:\n",
        "                msg = '\\n' + msg\n",
        "            print_log(msg, logger=logger)\n",
        "\n",
        "            if metric == 'proposal_fast':\n",
        "                ar = self.fast_eval_recall(\n",
        "                    results, proposal_nums, iou_thrs, logger='silent')\n",
        "                log_msg = []\n",
        "                for i, num in enumerate(proposal_nums):\n",
        "                    eval_results[f'AR@{num}'] = ar[i]\n",
        "                    log_msg.append(f'\\nAR@{num}\\t{ar[i]:.4f}')\n",
        "                log_msg = ''.join(log_msg)\n",
        "                print_log(log_msg, logger=logger)\n",
        "                continue\n",
        "\n",
        "            if metric not in result_files:\n",
        "                raise KeyError(f'{metric} is not in results')\n",
        "            try:\n",
        "                cocoDt = cocoGt.loadRes(result_files[metric])\n",
        "            except IndexError:\n",
        "                print_log(\n",
        "                    'The testing results of the whole dataset is empty.',\n",
        "                    logger=logger,\n",
        "                    level=logging.ERROR)\n",
        "                break\n",
        "\n",
        "            iou_type = 'bbox' if metric == 'proposal' else metric\n",
        "            cocoEval = COCOeval(cocoGt, cocoDt, iou_type)\n",
        "            cocoEval.params.catIds = self.cat_ids\n",
        "            cocoEval.params.imgIds = self.img_ids\n",
        "            cocoEval.params.maxDets = list(proposal_nums)\n",
        "            cocoEval.params.iouThrs = iou_thrs\n",
        "            # mapping of cocoEval.stats\n",
        "            coco_metric_names = {\n",
        "                'mAP': 0,\n",
        "                'mAP_50': 1,\n",
        "                'mAP_75': 2,\n",
        "                'mAP_s': 3,\n",
        "                'mAP_m': 4,\n",
        "                'mAP_l': 5,\n",
        "                'AR@100': 6,\n",
        "                'AR@300': 7,\n",
        "                'AR@1000': 8,\n",
        "                'AR_s@1000': 9,\n",
        "                'AR_m@1000': 10,\n",
        "                'AR_l@1000': 11\n",
        "            }\n",
        "            if metric_items is not None:\n",
        "                for metric_item in metric_items:\n",
        "                    if metric_item not in coco_metric_names:\n",
        "                        raise KeyError(\n",
        "                            f'metric item {metric_item} is not supported')\n",
        "\n",
        "            if metric == 'proposal':\n",
        "                cocoEval.params.useCats = 0\n",
        "                cocoEval.evaluate()\n",
        "                cocoEval.accumulate()\n",
        "                cocoEval.summarize()\n",
        "                if metric_items is None:\n",
        "                    metric_items = [\n",
        "                        'AR@100', 'AR@300', 'AR@1000', 'AR_s@1000',\n",
        "                        'AR_m@1000', 'AR_l@1000'\n",
        "                    ]\n",
        "\n",
        "                for item in metric_items:\n",
        "                    val = float(\n",
        "                        f'{cocoEval.stats[coco_metric_names[item]]:.3f}')\n",
        "                    eval_results[item] = val\n",
        "            else:\n",
        "                cocoEval.evaluate()\n",
        "                cocoEval.accumulate()\n",
        "                cocoEval.summarize()\n",
        "                if classwise:  # Compute per-category AP\n",
        "                    # Compute per-category AP\n",
        "                    # from https://github.com/facebookresearch/detectron2/\n",
        "                    precisions = cocoEval.eval['precision']\n",
        "                    # precision: (iou, recall, cls, area range, max dets)\n",
        "                    assert len(self.cat_ids) == precisions.shape[2]\n",
        "\n",
        "                    results_per_category = []\n",
        "                    for idx, catId in enumerate(self.cat_ids):\n",
        "                        # area range index 0: all area ranges\n",
        "                        # max dets index -1: typically 100 per image\n",
        "                        nm = self.coco.loadCats(catId)[0]\n",
        "                        precision = precisions[:, :, idx, 0, -1]\n",
        "                        precision = precision[precision > -1]\n",
        "                        if precision.size:\n",
        "                            ap = np.mean(precision)\n",
        "                        else:\n",
        "                            ap = float('nan')\n",
        "                        results_per_category.append(\n",
        "                            (f'{nm[\"name\"]}', f'{float(ap):0.3f}'))\n",
        "\n",
        "                    num_columns = min(6, len(results_per_category) * 2)\n",
        "                    results_flatten = list(\n",
        "                        itertools.chain(*results_per_category))\n",
        "                    headers = ['category', 'AP'] * (num_columns // 2)\n",
        "                    results_2d = itertools.zip_longest(*[\n",
        "                        results_flatten[i::num_columns]\n",
        "                        for i in range(num_columns)\n",
        "                    ])\n",
        "                    table_data = [headers]\n",
        "                    table_data += [result for result in results_2d]\n",
        "                    table = AsciiTable(table_data)\n",
        "                    print_log('\\n' + table.table, logger=logger)\n",
        "\n",
        "                if metric_items is None:\n",
        "                    metric_items = [\n",
        "                        'mAP', 'mAP_50', 'mAP_75', 'mAP_s', 'mAP_m', 'mAP_l'\n",
        "                    ]\n",
        "\n",
        "                for metric_item in metric_items:\n",
        "                    key = f'{metric}_{metric_item}'\n",
        "                    val = float(\n",
        "                        f'{cocoEval.stats[coco_metric_names[metric_item]]:.3f}'\n",
        "                    )\n",
        "                    eval_results[key] = val\n",
        "                ap = cocoEval.stats[:6]\n",
        "                eval_results[f'{metric}_mAP_copypaste'] = (\n",
        "                    f'{ap[0]:.3f} {ap[1]:.3f} {ap[2]:.3f} {ap[3]:.3f} '\n",
        "                    f'{ap[4]:.3f} {ap[5]:.3f}')\n",
        "        if tmp_dir is not None:\n",
        "            tmp_dir.cleanup()\n",
        "        return eval_results\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "yf_LxeMHpJuE"
      },
      "source": [
        "#@title mask_rcnn_r50_fpn.py (config classes)\n",
        "%%writefile /content/mmdetection/configs/_base_/models/mask_rcnn_r50_fpn.py\n",
        "# model settings\n",
        "model = dict(\n",
        "    type='MaskRCNN',\n",
        "    pretrained='torchvision://resnet50',\n",
        "    backbone=dict(\n",
        "        type='ResNet',\n",
        "        depth=50,\n",
        "        num_stages=4,\n",
        "        out_indices=(0, 1, 2, 3),\n",
        "        frozen_stages=1,\n",
        "        norm_cfg=dict(type='BN', requires_grad=True),\n",
        "        norm_eval=True,\n",
        "        style='pytorch'),\n",
        "    neck=dict(\n",
        "        type='FPN',\n",
        "        in_channels=[256, 512, 1024, 2048],\n",
        "        out_channels=256,\n",
        "        num_outs=5),\n",
        "    rpn_head=dict(\n",
        "        type='RPNHead',\n",
        "        in_channels=256,\n",
        "        feat_channels=256,\n",
        "        anchor_generator=dict(\n",
        "            type='AnchorGenerator',\n",
        "            scales=[8],\n",
        "            ratios=[0.5, 1.0, 2.0],\n",
        "            strides=[4, 8, 16, 32, 64]),\n",
        "        bbox_coder=dict(\n",
        "            type='DeltaXYWHBBoxCoder',\n",
        "            target_means=[.0, .0, .0, .0],\n",
        "            target_stds=[1.0, 1.0, 1.0, 1.0]),\n",
        "        loss_cls=dict(\n",
        "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\n",
        "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
        "    roi_head=dict(\n",
        "        type='StandardRoIHead',\n",
        "        bbox_roi_extractor=dict(\n",
        "            type='SingleRoIExtractor',\n",
        "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\n",
        "            out_channels=256,\n",
        "            featmap_strides=[4, 8, 16, 32]),\n",
        "        bbox_head=dict(\n",
        "            type='Shared2FCBBoxHead',\n",
        "            in_channels=256,\n",
        "            fc_out_channels=1024,\n",
        "            roi_feat_size=7,\n",
        "            num_classes=4,\n",
        "            bbox_coder=dict(\n",
        "                type='DeltaXYWHBBoxCoder',\n",
        "                target_means=[0., 0., 0., 0.],\n",
        "                target_stds=[0.1, 0.1, 0.2, 0.2]),\n",
        "            reg_class_agnostic=False,\n",
        "            loss_cls=dict(\n",
        "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\n",
        "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\n",
        "        mask_roi_extractor=dict(\n",
        "            type='SingleRoIExtractor',\n",
        "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\n",
        "            out_channels=256,\n",
        "            featmap_strides=[4, 8, 16, 32]),\n",
        "        mask_head=dict(\n",
        "            type='FCNMaskHead',\n",
        "            num_convs=4,\n",
        "            in_channels=256,\n",
        "            conv_out_channels=256,\n",
        "            num_classes=4,\n",
        "            loss_mask=dict(\n",
        "                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\n",
        "    # model training and testing settings\n",
        "    train_cfg=dict(\n",
        "        rpn=dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssigner',\n",
        "                pos_iou_thr=0.7,\n",
        "                neg_iou_thr=0.3,\n",
        "                min_pos_iou=0.3,\n",
        "                match_low_quality=True,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomSampler',\n",
        "                num=256,\n",
        "                pos_fraction=0.5,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=False),\n",
        "            allowed_border=-1,\n",
        "            pos_weight=-1,\n",
        "            debug=False),\n",
        "        rpn_proposal=dict(\n",
        "            nms_across_levels=False,\n",
        "            nms_pre=2000,\n",
        "            nms_post=1000,\n",
        "            max_num=1000,\n",
        "            nms_thr=0.7,\n",
        "            min_bbox_size=0),\n",
        "        rcnn=dict(\n",
        "            assigner=dict(\n",
        "                type='MaxIoUAssigner',\n",
        "                pos_iou_thr=0.5,\n",
        "                neg_iou_thr=0.5,\n",
        "                min_pos_iou=0.5,\n",
        "                match_low_quality=True,\n",
        "                ignore_iof_thr=-1),\n",
        "            sampler=dict(\n",
        "                type='RandomSampler',\n",
        "                num=512,\n",
        "                pos_fraction=0.25,\n",
        "                neg_pos_ub=-1,\n",
        "                add_gt_as_proposals=True),\n",
        "            mask_size=28,\n",
        "            pos_weight=-1,\n",
        "            debug=False)),\n",
        "    test_cfg=dict(\n",
        "        rpn=dict(\n",
        "            nms_across_levels=False,\n",
        "            nms_pre=1000,\n",
        "            nms_post=1000,\n",
        "            max_num=1000,\n",
        "            nms_thr=0.7,\n",
        "            min_bbox_size=0),\n",
        "        rcnn=dict(\n",
        "            score_thr=0.05,\n",
        "            nms=dict(type='nms', iou_threshold=0.5),\n",
        "            max_per_img=100,\n",
        "            mask_thr_binary=0.5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "zl8PeWHRtZuI"
      },
      "source": [
        "#@title coco_instance.py (config paths)\n",
        "%%writefile /content/mmdetection/configs/_base_/datasets/coco_instance.py \n",
        "dataset_type = 'CocoDataset'\n",
        "data_root = 'data/coco/'\n",
        "img_norm_cfg = dict(\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\n",
        "train_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\n",
        "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\n",
        "    dict(type='RandomFlip', flip_ratio=0.5),\n",
        "    dict(type='Normalize', **img_norm_cfg),\n",
        "    dict(type='Pad', size_divisor=32),\n",
        "    dict(type='DefaultFormatBundle'),\n",
        "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),\n",
        "]\n",
        "test_pipeline = [\n",
        "    dict(type='LoadImageFromFile'),\n",
        "    dict(\n",
        "        type='MultiScaleFlipAug',\n",
        "        img_scale=(1333, 800),\n",
        "        flip=False,\n",
        "        transforms=[\n",
        "            dict(type='Resize', keep_ratio=True),\n",
        "            dict(type='RandomFlip'),\n",
        "            dict(type='Normalize', **img_norm_cfg),\n",
        "            dict(type='Pad', size_divisor=32),\n",
        "            dict(type='ImageToTensor', keys=['img']),\n",
        "            dict(type='Collect', keys=['img']),\n",
        "        ])\n",
        "]\n",
        "data = dict(\n",
        "    samples_per_gpu=2,\n",
        "    workers_per_gpu=2,\n",
        "    train=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file='/content/object_detection/images/train.json',\n",
        "        img_prefix='/content/object_detection/images/train/',\n",
        "        pipeline=train_pipeline),\n",
        "    val=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file='/content/object_detection/images/test.json',\n",
        "        img_prefix='/content/object_detection/images/test/',\n",
        "        pipeline=test_pipeline),\n",
        "    test=dict(\n",
        "        type=dataset_type,\n",
        "        ann_file='/content/object_detection/images/test.json',\n",
        "        img_prefix='/content/object_detection/images/test',\n",
        "        pipeline=test_pipeline))\n",
        "evaluation = dict(metric=['bbox', 'segm'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80YS443TrIpG"
      },
      "source": [
        "[TannerGilbert/Tensorflow-Object-Detection-API-train-custom-Mask-R-CNN-model](https://github.com/TannerGilbert/Tensorflow-Object-Detection-API-train-custom-Mask-R-CNN-model) contains a small coco dataset, which is used as a test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBWg1M3wrJ4z"
      },
      "source": [
        "%cd /content/\n",
        "!git clone https://github.com/TannerGilbert/Tensorflow-Object-Detection-API-train-custom-Mask-R-CNN-model object_detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHgPqcFRnwP9"
      },
      "source": [
        "#https://github.com/open-mmlab/mmdetection/issues/3305\n",
        "%cd /content/mmdetection\n",
        "!python tools/train.py /content/mmdetection/configs/mask_rcnn/mask_rcnn_r50_fpn_2x_coco.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agmqKBeK1GOK"
      },
      "source": [
        "# Test\n",
        "Models are now in ```/content/mmdetection/work_dirs/mask_rcnn_r50_fpn_2x_coco/``` and can be used. Testing output will be in the same path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n10gkCSYl9CE",
        "cellView": "form"
      },
      "source": [
        "#@title Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "print('Google Drive connected.')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNRy702z3g05"
      },
      "source": [
        "%cd /content/mmdetection\n",
        "!python tools/test.py \\\n",
        "    /content/test.py \\\n",
        "    /content/drive/MyDrive/mmdetection/mask_rcnn_r50_fpn_2x_coco/epoch_3.pth \\\n",
        "    --eval \"bbox\" \\\n",
        "    --show-dir /content/output/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mdVMfg15SAf",
        "cellView": "form"
      },
      "source": [
        "#@title show one example\n",
        "from IPython.display import Image\n",
        "Image('/content/mmdetection/work_dirs/mask_rcnn_r50_fpn_2x_coco/test.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
