{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Colab-mmdetection.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XERPLVn0vDi"
      },
      "source": [
        "# Colab-mmdetection\r\n",
        "\r\n",
        "Original repo: [open-mmlab/mmdetection](https://github.com/open-mmlab/mmdetection)\r\n",
        "\r\n",
        "Also thanks to this [issue](https://github.com/open-mmlab/mmdetection/issues/3305)\r\n",
        "\r\n",
        "My fork: [styler00dollar/Colab-mmdetection](https://github.com/styler00dollar/Colab-mmdetection)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADCrJ9ZXt3yH"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "O-X3nDDMppBw"
      },
      "source": [
        "#@title install\r\n",
        "# install dependencies: (use cu101 because colab has CUDA 10.1)\r\n",
        "!pip install -U torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\r\n",
        "\r\n",
        "# install mmcv-full thus we could use CUDA operators\r\n",
        "!pip install mmcv-full\r\n",
        "\r\n",
        "# Install mmdetection\r\n",
        "!rm -rf mmdetection\r\n",
        "!git clone https://github.com/open-mmlab/mmdetection.git\r\n",
        "%cd mmdetection\r\n",
        "\r\n",
        "!pip install -e .\r\n",
        "\r\n",
        "# install Pillow 7.0.0 back in order to avoid bug in colab\r\n",
        "!pip install Pillow==7.0.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pw3gJtwx2-x8"
      },
      "source": [
        "# Train\r\n",
        "Example usage with ```mask_rcnn_r50_fpn_2x_coco.py```. For a coco dataset it is needed to change the amount of classes inside the ```coco.py``` file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "PBA4OIhyo1Na"
      },
      "source": [
        "#@title coco.py (config classes)\r\n",
        "%%writefile /content/mmdetection/mmdet/datasets/coco.py\r\n",
        "import itertools\r\n",
        "import logging\r\n",
        "import os.path as osp\r\n",
        "import tempfile\r\n",
        "from collections import OrderedDict\r\n",
        "\r\n",
        "import mmcv\r\n",
        "import numpy as np\r\n",
        "from mmcv.utils import print_log\r\n",
        "from pycocotools.coco import COCO\r\n",
        "from pycocotools.cocoeval import COCOeval\r\n",
        "from terminaltables import AsciiTable\r\n",
        "\r\n",
        "from mmdet.core import eval_recalls\r\n",
        "from .builder import DATASETS\r\n",
        "from .custom import CustomDataset\r\n",
        "\r\n",
        "try:\r\n",
        "    import pycocotools\r\n",
        "    if not hasattr(pycocotools, '__sphinx_mock__'):  # for doc generation\r\n",
        "        assert pycocotools.__version__ >= '12.0.2'\r\n",
        "except AssertionError:\r\n",
        "    raise AssertionError('Incompatible version of pycocotools is installed. '\r\n",
        "                         'Run pip uninstall pycocotools first. Then run pip '\r\n",
        "                         'install mmpycocotools to install open-mmlab forked '\r\n",
        "                         'pycocotools.')\r\n",
        "\r\n",
        "\r\n",
        "@DATASETS.register_module()\r\n",
        "class CocoDataset(CustomDataset):\r\n",
        "    \"\"\"\r\n",
        "    CLASSES = ('person', 'bicycle', 'car', 'motorcycle', 'airplane', 'bus',\r\n",
        "               'train', 'truck', 'boat', 'traffic light', 'fire hydrant',\r\n",
        "               'stop sign', 'parking meter', 'bench', 'bird', 'cat', 'dog',\r\n",
        "               'horse', 'sheep', 'cow', 'elephant', 'bear', 'zebra', 'giraffe',\r\n",
        "               'backpack', 'umbrella', 'handbag', 'tie', 'suitcase', 'frisbee',\r\n",
        "               'skis', 'snowboard', 'sports ball', 'kite', 'baseball bat',\r\n",
        "               'baseball glove', 'skateboard', 'surfboard', 'tennis racket',\r\n",
        "               'bottle', 'wine glass', 'cup', 'fork', 'knife', 'spoon', 'bowl',\r\n",
        "               'banana', 'apple', 'sandwich', 'orange', 'broccoli', 'carrot',\r\n",
        "               'hot dog', 'pizza', 'donut', 'cake', 'chair', 'couch',\r\n",
        "               'potted plant', 'bed', 'dining table', 'toilet', 'tv', 'laptop',\r\n",
        "               'mouse', 'remote', 'keyboard', 'cell phone', 'microwave',\r\n",
        "               'oven', 'toaster', 'sink', 'refrigerator', 'book', 'clock',\r\n",
        "               'vase', 'scissors', 'teddy bear', 'hair drier', 'toothbrush')\r\n",
        "    \"\"\"\r\n",
        "    CLASSES = ('Arduino', 'ESP8266', 'Heltec', 'Raspberry')\r\n",
        "\r\n",
        "    def load_annotations(self, ann_file):\r\n",
        "        \"\"\"Load annotation from COCO style annotation file.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            ann_file (str): Path of annotation file.\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            list[dict]: Annotation info from COCO api.\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        self.coco = COCO(ann_file)\r\n",
        "        self.cat_ids = self.coco.get_cat_ids(cat_names=self.CLASSES)\r\n",
        "        self.cat2label = {cat_id: i for i, cat_id in enumerate(self.cat_ids)}\r\n",
        "        self.img_ids = self.coco.get_img_ids()\r\n",
        "        data_infos = []\r\n",
        "        for i in self.img_ids:\r\n",
        "            info = self.coco.load_imgs([i])[0]\r\n",
        "            info['filename'] = info['file_name']\r\n",
        "            data_infos.append(info)\r\n",
        "        return data_infos\r\n",
        "\r\n",
        "    def get_ann_info(self, idx):\r\n",
        "        \"\"\"Get COCO annotation by index.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            idx (int): Index of data.\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            dict: Annotation info of specified index.\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        img_id = self.data_infos[idx]['id']\r\n",
        "        ann_ids = self.coco.get_ann_ids(img_ids=[img_id])\r\n",
        "        ann_info = self.coco.load_anns(ann_ids)\r\n",
        "        return self._parse_ann_info(self.data_infos[idx], ann_info)\r\n",
        "\r\n",
        "    def get_cat_ids(self, idx):\r\n",
        "        \"\"\"Get COCO category ids by index.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            idx (int): Index of data.\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            list[int]: All categories in the image of specified index.\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        img_id = self.data_infos[idx]['id']\r\n",
        "        ann_ids = self.coco.get_ann_ids(img_ids=[img_id])\r\n",
        "        ann_info = self.coco.load_anns(ann_ids)\r\n",
        "        return [ann['category_id'] for ann in ann_info]\r\n",
        "\r\n",
        "    def _filter_imgs(self, min_size=32):\r\n",
        "        \"\"\"Filter images too small or without ground truths.\"\"\"\r\n",
        "        valid_inds = []\r\n",
        "        # obtain images that contain annotation\r\n",
        "        ids_with_ann = set(_['image_id'] for _ in self.coco.anns.values())\r\n",
        "        # obtain images that contain annotations of the required categories\r\n",
        "        ids_in_cat = set()\r\n",
        "        for i, class_id in enumerate(self.cat_ids):\r\n",
        "            ids_in_cat |= set(self.coco.cat_img_map[class_id])\r\n",
        "        # merge the image id sets of the two conditions and use the merged set\r\n",
        "        # to filter out images if self.filter_empty_gt=True\r\n",
        "        ids_in_cat &= ids_with_ann\r\n",
        "\r\n",
        "        valid_img_ids = []\r\n",
        "        for i, img_info in enumerate(self.data_infos):\r\n",
        "            img_id = self.img_ids[i]\r\n",
        "            if self.filter_empty_gt and img_id not in ids_in_cat:\r\n",
        "                continue\r\n",
        "            if min(img_info['width'], img_info['height']) >= min_size:\r\n",
        "                valid_inds.append(i)\r\n",
        "                valid_img_ids.append(img_id)\r\n",
        "        self.img_ids = valid_img_ids\r\n",
        "        return valid_inds\r\n",
        "\r\n",
        "    def _parse_ann_info(self, img_info, ann_info):\r\n",
        "        \"\"\"Parse bbox and mask annotation.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            ann_info (list[dict]): Annotation info of an image.\r\n",
        "            with_mask (bool): Whether to parse mask annotations.\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            dict: A dict containing the following keys: bboxes, bboxes_ignore,\\\r\n",
        "                labels, masks, seg_map. \"masks\" are raw annotations and not \\\r\n",
        "                decoded into binary masks.\r\n",
        "        \"\"\"\r\n",
        "        gt_bboxes = []\r\n",
        "        gt_labels = []\r\n",
        "        gt_bboxes_ignore = []\r\n",
        "        gt_masks_ann = []\r\n",
        "        for i, ann in enumerate(ann_info):\r\n",
        "            if ann.get('ignore', False):\r\n",
        "                continue\r\n",
        "            x1, y1, w, h = ann['bbox']\r\n",
        "            inter_w = max(0, min(x1 + w, img_info['width']) - max(x1, 0))\r\n",
        "            inter_h = max(0, min(y1 + h, img_info['height']) - max(y1, 0))\r\n",
        "            if inter_w * inter_h == 0:\r\n",
        "                continue\r\n",
        "            if ann['area'] <= 0 or w < 1 or h < 1:\r\n",
        "                continue\r\n",
        "            if ann['category_id'] not in self.cat_ids:\r\n",
        "                continue\r\n",
        "            bbox = [x1, y1, x1 + w, y1 + h]\r\n",
        "            if ann.get('iscrowd', False):\r\n",
        "                gt_bboxes_ignore.append(bbox)\r\n",
        "            else:\r\n",
        "                gt_bboxes.append(bbox)\r\n",
        "                gt_labels.append(self.cat2label[ann['category_id']])\r\n",
        "                gt_masks_ann.append(ann.get('segmentation', None))\r\n",
        "\r\n",
        "        if gt_bboxes:\r\n",
        "            gt_bboxes = np.array(gt_bboxes, dtype=np.float32)\r\n",
        "            gt_labels = np.array(gt_labels, dtype=np.int64)\r\n",
        "        else:\r\n",
        "            gt_bboxes = np.zeros((0, 4), dtype=np.float32)\r\n",
        "            gt_labels = np.array([], dtype=np.int64)\r\n",
        "\r\n",
        "        if gt_bboxes_ignore:\r\n",
        "            gt_bboxes_ignore = np.array(gt_bboxes_ignore, dtype=np.float32)\r\n",
        "        else:\r\n",
        "            gt_bboxes_ignore = np.zeros((0, 4), dtype=np.float32)\r\n",
        "\r\n",
        "        seg_map = img_info['filename'].replace('jpg', 'png')\r\n",
        "\r\n",
        "        ann = dict(\r\n",
        "            bboxes=gt_bboxes,\r\n",
        "            labels=gt_labels,\r\n",
        "            bboxes_ignore=gt_bboxes_ignore,\r\n",
        "            masks=gt_masks_ann,\r\n",
        "            seg_map=seg_map)\r\n",
        "\r\n",
        "        return ann\r\n",
        "\r\n",
        "    def xyxy2xywh(self, bbox):\r\n",
        "        \"\"\"Convert ``xyxy`` style bounding boxes to ``xywh`` style for COCO\r\n",
        "        evaluation.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            bbox (numpy.ndarray): The bounding boxes, shape (4, ), in\r\n",
        "                ``xyxy`` order.\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            list[float]: The converted bounding boxes, in ``xywh`` order.\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        _bbox = bbox.tolist()\r\n",
        "        return [\r\n",
        "            _bbox[0],\r\n",
        "            _bbox[1],\r\n",
        "            _bbox[2] - _bbox[0],\r\n",
        "            _bbox[3] - _bbox[1],\r\n",
        "        ]\r\n",
        "\r\n",
        "    def _proposal2json(self, results):\r\n",
        "        \"\"\"Convert proposal results to COCO json style.\"\"\"\r\n",
        "        json_results = []\r\n",
        "        for idx in range(len(self)):\r\n",
        "            img_id = self.img_ids[idx]\r\n",
        "            bboxes = results[idx]\r\n",
        "            for i in range(bboxes.shape[0]):\r\n",
        "                data = dict()\r\n",
        "                data['image_id'] = img_id\r\n",
        "                data['bbox'] = self.xyxy2xywh(bboxes[i])\r\n",
        "                data['score'] = float(bboxes[i][4])\r\n",
        "                data['category_id'] = 1\r\n",
        "                json_results.append(data)\r\n",
        "        return json_results\r\n",
        "\r\n",
        "    def _det2json(self, results):\r\n",
        "        \"\"\"Convert detection results to COCO json style.\"\"\"\r\n",
        "        json_results = []\r\n",
        "        for idx in range(len(self)):\r\n",
        "            img_id = self.img_ids[idx]\r\n",
        "            result = results[idx]\r\n",
        "            for label in range(len(result)):\r\n",
        "                bboxes = result[label]\r\n",
        "                for i in range(bboxes.shape[0]):\r\n",
        "                    data = dict()\r\n",
        "                    data['image_id'] = img_id\r\n",
        "                    data['bbox'] = self.xyxy2xywh(bboxes[i])\r\n",
        "                    data['score'] = float(bboxes[i][4])\r\n",
        "                    data['category_id'] = self.cat_ids[label]\r\n",
        "                    json_results.append(data)\r\n",
        "        return json_results\r\n",
        "\r\n",
        "    def _segm2json(self, results):\r\n",
        "        \"\"\"Convert instance segmentation results to COCO json style.\"\"\"\r\n",
        "        bbox_json_results = []\r\n",
        "        segm_json_results = []\r\n",
        "        for idx in range(len(self)):\r\n",
        "            img_id = self.img_ids[idx]\r\n",
        "            det, seg = results[idx]\r\n",
        "            for label in range(len(det)):\r\n",
        "                # bbox results\r\n",
        "                bboxes = det[label]\r\n",
        "                for i in range(bboxes.shape[0]):\r\n",
        "                    data = dict()\r\n",
        "                    data['image_id'] = img_id\r\n",
        "                    data['bbox'] = self.xyxy2xywh(bboxes[i])\r\n",
        "                    data['score'] = float(bboxes[i][4])\r\n",
        "                    data['category_id'] = self.cat_ids[label]\r\n",
        "                    bbox_json_results.append(data)\r\n",
        "\r\n",
        "                # segm results\r\n",
        "                # some detectors use different scores for bbox and mask\r\n",
        "                if isinstance(seg, tuple):\r\n",
        "                    segms = seg[0][label]\r\n",
        "                    mask_score = seg[1][label]\r\n",
        "                else:\r\n",
        "                    segms = seg[label]\r\n",
        "                    mask_score = [bbox[4] for bbox in bboxes]\r\n",
        "                for i in range(bboxes.shape[0]):\r\n",
        "                    data = dict()\r\n",
        "                    data['image_id'] = img_id\r\n",
        "                    data['bbox'] = self.xyxy2xywh(bboxes[i])\r\n",
        "                    data['score'] = float(mask_score[i])\r\n",
        "                    data['category_id'] = self.cat_ids[label]\r\n",
        "                    if isinstance(segms[i]['counts'], bytes):\r\n",
        "                        segms[i]['counts'] = segms[i]['counts'].decode()\r\n",
        "                    data['segmentation'] = segms[i]\r\n",
        "                    segm_json_results.append(data)\r\n",
        "        return bbox_json_results, segm_json_results\r\n",
        "\r\n",
        "    def results2json(self, results, outfile_prefix):\r\n",
        "        \"\"\"Dump the detection results to a COCO style json file.\r\n",
        "\r\n",
        "        There are 3 types of results: proposals, bbox predictions, mask\r\n",
        "        predictions, and they have different data types. This method will\r\n",
        "        automatically recognize the type, and dump them to json files.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            results (list[list | tuple | ndarray]): Testing results of the\r\n",
        "                dataset.\r\n",
        "            outfile_prefix (str): The filename prefix of the json files. If the\r\n",
        "                prefix is \"somepath/xxx\", the json files will be named\r\n",
        "                \"somepath/xxx.bbox.json\", \"somepath/xxx.segm.json\",\r\n",
        "                \"somepath/xxx.proposal.json\".\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            dict[str: str]: Possible keys are \"bbox\", \"segm\", \"proposal\", and \\\r\n",
        "                values are corresponding filenames.\r\n",
        "        \"\"\"\r\n",
        "        result_files = dict()\r\n",
        "        if isinstance(results[0], list):\r\n",
        "            json_results = self._det2json(results)\r\n",
        "            result_files['bbox'] = f'{outfile_prefix}.bbox.json'\r\n",
        "            result_files['proposal'] = f'{outfile_prefix}.bbox.json'\r\n",
        "            mmcv.dump(json_results, result_files['bbox'])\r\n",
        "        elif isinstance(results[0], tuple):\r\n",
        "            json_results = self._segm2json(results)\r\n",
        "            result_files['bbox'] = f'{outfile_prefix}.bbox.json'\r\n",
        "            result_files['proposal'] = f'{outfile_prefix}.bbox.json'\r\n",
        "            result_files['segm'] = f'{outfile_prefix}.segm.json'\r\n",
        "            mmcv.dump(json_results[0], result_files['bbox'])\r\n",
        "            mmcv.dump(json_results[1], result_files['segm'])\r\n",
        "        elif isinstance(results[0], np.ndarray):\r\n",
        "            json_results = self._proposal2json(results)\r\n",
        "            result_files['proposal'] = f'{outfile_prefix}.proposal.json'\r\n",
        "            mmcv.dump(json_results, result_files['proposal'])\r\n",
        "        else:\r\n",
        "            raise TypeError('invalid type of results')\r\n",
        "        return result_files\r\n",
        "\r\n",
        "    def fast_eval_recall(self, results, proposal_nums, iou_thrs, logger=None):\r\n",
        "        gt_bboxes = []\r\n",
        "        for i in range(len(self.img_ids)):\r\n",
        "            ann_ids = self.coco.get_ann_ids(img_ids=self.img_ids[i])\r\n",
        "            ann_info = self.coco.load_anns(ann_ids)\r\n",
        "            if len(ann_info) == 0:\r\n",
        "                gt_bboxes.append(np.zeros((0, 4)))\r\n",
        "                continue\r\n",
        "            bboxes = []\r\n",
        "            for ann in ann_info:\r\n",
        "                if ann.get('ignore', False) or ann['iscrowd']:\r\n",
        "                    continue\r\n",
        "                x1, y1, w, h = ann['bbox']\r\n",
        "                bboxes.append([x1, y1, x1 + w, y1 + h])\r\n",
        "            bboxes = np.array(bboxes, dtype=np.float32)\r\n",
        "            if bboxes.shape[0] == 0:\r\n",
        "                bboxes = np.zeros((0, 4))\r\n",
        "            gt_bboxes.append(bboxes)\r\n",
        "\r\n",
        "        recalls = eval_recalls(\r\n",
        "            gt_bboxes, results, proposal_nums, iou_thrs, logger=logger)\r\n",
        "        ar = recalls.mean(axis=1)\r\n",
        "        return ar\r\n",
        "\r\n",
        "    def format_results(self, results, jsonfile_prefix=None, **kwargs):\r\n",
        "        \"\"\"Format the results to json (standard format for COCO evaluation).\r\n",
        "\r\n",
        "        Args:\r\n",
        "            results (list[tuple | numpy.ndarray]): Testing results of the\r\n",
        "                dataset.\r\n",
        "            jsonfile_prefix (str | None): The prefix of json files. It includes\r\n",
        "                the file path and the prefix of filename, e.g., \"a/b/prefix\".\r\n",
        "                If not specified, a temp file will be created. Default: None.\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            tuple: (result_files, tmp_dir), result_files is a dict containing \\\r\n",
        "                the json filepaths, tmp_dir is the temporal directory created \\\r\n",
        "                for saving json files when jsonfile_prefix is not specified.\r\n",
        "        \"\"\"\r\n",
        "        assert isinstance(results, list), 'results must be a list'\r\n",
        "        assert len(results) == len(self), (\r\n",
        "            'The length of results is not equal to the dataset len: {} != {}'.\r\n",
        "            format(len(results), len(self)))\r\n",
        "\r\n",
        "        if jsonfile_prefix is None:\r\n",
        "            tmp_dir = tempfile.TemporaryDirectory()\r\n",
        "            jsonfile_prefix = osp.join(tmp_dir.name, 'results')\r\n",
        "        else:\r\n",
        "            tmp_dir = None\r\n",
        "        result_files = self.results2json(results, jsonfile_prefix)\r\n",
        "        return result_files, tmp_dir\r\n",
        "\r\n",
        "    def evaluate(self,\r\n",
        "                 results,\r\n",
        "                 metric='bbox',\r\n",
        "                 logger=None,\r\n",
        "                 jsonfile_prefix=None,\r\n",
        "                 classwise=False,\r\n",
        "                 proposal_nums=(100, 300, 1000),\r\n",
        "                 iou_thrs=None,\r\n",
        "                 metric_items=None):\r\n",
        "        \"\"\"Evaluation in COCO protocol.\r\n",
        "\r\n",
        "        Args:\r\n",
        "            results (list[list | tuple]): Testing results of the dataset.\r\n",
        "            metric (str | list[str]): Metrics to be evaluated. Options are\r\n",
        "                'bbox', 'segm', 'proposal', 'proposal_fast'.\r\n",
        "            logger (logging.Logger | str | None): Logger used for printing\r\n",
        "                related information during evaluation. Default: None.\r\n",
        "            jsonfile_prefix (str | None): The prefix of json files. It includes\r\n",
        "                the file path and the prefix of filename, e.g., \"a/b/prefix\".\r\n",
        "                If not specified, a temp file will be created. Default: None.\r\n",
        "            classwise (bool): Whether to evaluating the AP for each class.\r\n",
        "            proposal_nums (Sequence[int]): Proposal number used for evaluating\r\n",
        "                recalls, such as recall@100, recall@1000.\r\n",
        "                Default: (100, 300, 1000).\r\n",
        "            iou_thrs (Sequence[float], optional): IoU threshold used for\r\n",
        "                evaluating recalls/mAPs. If set to a list, the average of all\r\n",
        "                IoUs will also be computed. If not specified, [0.50, 0.55,\r\n",
        "                0.60, 0.65, 0.70, 0.75, 0.80, 0.85, 0.90, 0.95] will be used.\r\n",
        "                Default: None.\r\n",
        "            metric_items (list[str] | str, optional): Metric items that will\r\n",
        "                be returned. If not specified, ``['AR@100', 'AR@300',\r\n",
        "                'AR@1000', 'AR_s@1000', 'AR_m@1000', 'AR_l@1000' ]`` will be\r\n",
        "                used when ``metric=='proposal'``, ``['mAP', 'mAP_50', 'mAP_75',\r\n",
        "                'mAP_s', 'mAP_m', 'mAP_l']`` will be used when\r\n",
        "                ``metric=='bbox' or metric=='segm'``.\r\n",
        "\r\n",
        "        Returns:\r\n",
        "            dict[str, float]: COCO style evaluation metric.\r\n",
        "        \"\"\"\r\n",
        "\r\n",
        "        metrics = metric if isinstance(metric, list) else [metric]\r\n",
        "        allowed_metrics = ['bbox', 'segm', 'proposal', 'proposal_fast']\r\n",
        "        for metric in metrics:\r\n",
        "            if metric not in allowed_metrics:\r\n",
        "                raise KeyError(f'metric {metric} is not supported')\r\n",
        "        if iou_thrs is None:\r\n",
        "            iou_thrs = np.linspace(\r\n",
        "                .5, 0.95, int(np.round((0.95 - .5) / .05)) + 1, endpoint=True)\r\n",
        "        if metric_items is not None:\r\n",
        "            if not isinstance(metric_items, list):\r\n",
        "                metric_items = [metric_items]\r\n",
        "\r\n",
        "        result_files, tmp_dir = self.format_results(results, jsonfile_prefix)\r\n",
        "\r\n",
        "        eval_results = OrderedDict()\r\n",
        "        cocoGt = self.coco\r\n",
        "        for metric in metrics:\r\n",
        "            msg = f'Evaluating {metric}...'\r\n",
        "            if logger is None:\r\n",
        "                msg = '\\n' + msg\r\n",
        "            print_log(msg, logger=logger)\r\n",
        "\r\n",
        "            if metric == 'proposal_fast':\r\n",
        "                ar = self.fast_eval_recall(\r\n",
        "                    results, proposal_nums, iou_thrs, logger='silent')\r\n",
        "                log_msg = []\r\n",
        "                for i, num in enumerate(proposal_nums):\r\n",
        "                    eval_results[f'AR@{num}'] = ar[i]\r\n",
        "                    log_msg.append(f'\\nAR@{num}\\t{ar[i]:.4f}')\r\n",
        "                log_msg = ''.join(log_msg)\r\n",
        "                print_log(log_msg, logger=logger)\r\n",
        "                continue\r\n",
        "\r\n",
        "            if metric not in result_files:\r\n",
        "                raise KeyError(f'{metric} is not in results')\r\n",
        "            try:\r\n",
        "                cocoDt = cocoGt.loadRes(result_files[metric])\r\n",
        "            except IndexError:\r\n",
        "                print_log(\r\n",
        "                    'The testing results of the whole dataset is empty.',\r\n",
        "                    logger=logger,\r\n",
        "                    level=logging.ERROR)\r\n",
        "                break\r\n",
        "\r\n",
        "            iou_type = 'bbox' if metric == 'proposal' else metric\r\n",
        "            cocoEval = COCOeval(cocoGt, cocoDt, iou_type)\r\n",
        "            cocoEval.params.catIds = self.cat_ids\r\n",
        "            cocoEval.params.imgIds = self.img_ids\r\n",
        "            cocoEval.params.maxDets = list(proposal_nums)\r\n",
        "            cocoEval.params.iouThrs = iou_thrs\r\n",
        "            # mapping of cocoEval.stats\r\n",
        "            coco_metric_names = {\r\n",
        "                'mAP': 0,\r\n",
        "                'mAP_50': 1,\r\n",
        "                'mAP_75': 2,\r\n",
        "                'mAP_s': 3,\r\n",
        "                'mAP_m': 4,\r\n",
        "                'mAP_l': 5,\r\n",
        "                'AR@100': 6,\r\n",
        "                'AR@300': 7,\r\n",
        "                'AR@1000': 8,\r\n",
        "                'AR_s@1000': 9,\r\n",
        "                'AR_m@1000': 10,\r\n",
        "                'AR_l@1000': 11\r\n",
        "            }\r\n",
        "            if metric_items is not None:\r\n",
        "                for metric_item in metric_items:\r\n",
        "                    if metric_item not in coco_metric_names:\r\n",
        "                        raise KeyError(\r\n",
        "                            f'metric item {metric_item} is not supported')\r\n",
        "\r\n",
        "            if metric == 'proposal':\r\n",
        "                cocoEval.params.useCats = 0\r\n",
        "                cocoEval.evaluate()\r\n",
        "                cocoEval.accumulate()\r\n",
        "                cocoEval.summarize()\r\n",
        "                if metric_items is None:\r\n",
        "                    metric_items = [\r\n",
        "                        'AR@100', 'AR@300', 'AR@1000', 'AR_s@1000',\r\n",
        "                        'AR_m@1000', 'AR_l@1000'\r\n",
        "                    ]\r\n",
        "\r\n",
        "                for item in metric_items:\r\n",
        "                    val = float(\r\n",
        "                        f'{cocoEval.stats[coco_metric_names[item]]:.3f}')\r\n",
        "                    eval_results[item] = val\r\n",
        "            else:\r\n",
        "                cocoEval.evaluate()\r\n",
        "                cocoEval.accumulate()\r\n",
        "                cocoEval.summarize()\r\n",
        "                if classwise:  # Compute per-category AP\r\n",
        "                    # Compute per-category AP\r\n",
        "                    # from https://github.com/facebookresearch/detectron2/\r\n",
        "                    precisions = cocoEval.eval['precision']\r\n",
        "                    # precision: (iou, recall, cls, area range, max dets)\r\n",
        "                    assert len(self.cat_ids) == precisions.shape[2]\r\n",
        "\r\n",
        "                    results_per_category = []\r\n",
        "                    for idx, catId in enumerate(self.cat_ids):\r\n",
        "                        # area range index 0: all area ranges\r\n",
        "                        # max dets index -1: typically 100 per image\r\n",
        "                        nm = self.coco.loadCats(catId)[0]\r\n",
        "                        precision = precisions[:, :, idx, 0, -1]\r\n",
        "                        precision = precision[precision > -1]\r\n",
        "                        if precision.size:\r\n",
        "                            ap = np.mean(precision)\r\n",
        "                        else:\r\n",
        "                            ap = float('nan')\r\n",
        "                        results_per_category.append(\r\n",
        "                            (f'{nm[\"name\"]}', f'{float(ap):0.3f}'))\r\n",
        "\r\n",
        "                    num_columns = min(6, len(results_per_category) * 2)\r\n",
        "                    results_flatten = list(\r\n",
        "                        itertools.chain(*results_per_category))\r\n",
        "                    headers = ['category', 'AP'] * (num_columns // 2)\r\n",
        "                    results_2d = itertools.zip_longest(*[\r\n",
        "                        results_flatten[i::num_columns]\r\n",
        "                        for i in range(num_columns)\r\n",
        "                    ])\r\n",
        "                    table_data = [headers]\r\n",
        "                    table_data += [result for result in results_2d]\r\n",
        "                    table = AsciiTable(table_data)\r\n",
        "                    print_log('\\n' + table.table, logger=logger)\r\n",
        "\r\n",
        "                if metric_items is None:\r\n",
        "                    metric_items = [\r\n",
        "                        'mAP', 'mAP_50', 'mAP_75', 'mAP_s', 'mAP_m', 'mAP_l'\r\n",
        "                    ]\r\n",
        "\r\n",
        "                for metric_item in metric_items:\r\n",
        "                    key = f'{metric}_{metric_item}'\r\n",
        "                    val = float(\r\n",
        "                        f'{cocoEval.stats[coco_metric_names[metric_item]]:.3f}'\r\n",
        "                    )\r\n",
        "                    eval_results[key] = val\r\n",
        "                ap = cocoEval.stats[:6]\r\n",
        "                eval_results[f'{metric}_mAP_copypaste'] = (\r\n",
        "                    f'{ap[0]:.3f} {ap[1]:.3f} {ap[2]:.3f} {ap[3]:.3f} '\r\n",
        "                    f'{ap[4]:.3f} {ap[5]:.3f}')\r\n",
        "        if tmp_dir is not None:\r\n",
        "            tmp_dir.cleanup()\r\n",
        "        return eval_results\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "yf_LxeMHpJuE"
      },
      "source": [
        "#@title mask_rcnn_r50_fpn.py (config classes)\r\n",
        "%%writefile /content/mmdetection/configs/_base_/models/mask_rcnn_r50_fpn.py\r\n",
        "# model settings\r\n",
        "model = dict(\r\n",
        "    type='MaskRCNN',\r\n",
        "    pretrained='torchvision://resnet50',\r\n",
        "    backbone=dict(\r\n",
        "        type='ResNet',\r\n",
        "        depth=50,\r\n",
        "        num_stages=4,\r\n",
        "        out_indices=(0, 1, 2, 3),\r\n",
        "        frozen_stages=1,\r\n",
        "        norm_cfg=dict(type='BN', requires_grad=True),\r\n",
        "        norm_eval=True,\r\n",
        "        style='pytorch'),\r\n",
        "    neck=dict(\r\n",
        "        type='FPN',\r\n",
        "        in_channels=[256, 512, 1024, 2048],\r\n",
        "        out_channels=256,\r\n",
        "        num_outs=5),\r\n",
        "    rpn_head=dict(\r\n",
        "        type='RPNHead',\r\n",
        "        in_channels=256,\r\n",
        "        feat_channels=256,\r\n",
        "        anchor_generator=dict(\r\n",
        "            type='AnchorGenerator',\r\n",
        "            scales=[8],\r\n",
        "            ratios=[0.5, 1.0, 2.0],\r\n",
        "            strides=[4, 8, 16, 32, 64]),\r\n",
        "        bbox_coder=dict(\r\n",
        "            type='DeltaXYWHBBoxCoder',\r\n",
        "            target_means=[.0, .0, .0, .0],\r\n",
        "            target_stds=[1.0, 1.0, 1.0, 1.0]),\r\n",
        "        loss_cls=dict(\r\n",
        "            type='CrossEntropyLoss', use_sigmoid=True, loss_weight=1.0),\r\n",
        "        loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\r\n",
        "    roi_head=dict(\r\n",
        "        type='StandardRoIHead',\r\n",
        "        bbox_roi_extractor=dict(\r\n",
        "            type='SingleRoIExtractor',\r\n",
        "            roi_layer=dict(type='RoIAlign', output_size=7, sampling_ratio=0),\r\n",
        "            out_channels=256,\r\n",
        "            featmap_strides=[4, 8, 16, 32]),\r\n",
        "        bbox_head=dict(\r\n",
        "            type='Shared2FCBBoxHead',\r\n",
        "            in_channels=256,\r\n",
        "            fc_out_channels=1024,\r\n",
        "            roi_feat_size=7,\r\n",
        "            num_classes=4,\r\n",
        "            bbox_coder=dict(\r\n",
        "                type='DeltaXYWHBBoxCoder',\r\n",
        "                target_means=[0., 0., 0., 0.],\r\n",
        "                target_stds=[0.1, 0.1, 0.2, 0.2]),\r\n",
        "            reg_class_agnostic=False,\r\n",
        "            loss_cls=dict(\r\n",
        "                type='CrossEntropyLoss', use_sigmoid=False, loss_weight=1.0),\r\n",
        "            loss_bbox=dict(type='L1Loss', loss_weight=1.0)),\r\n",
        "        mask_roi_extractor=dict(\r\n",
        "            type='SingleRoIExtractor',\r\n",
        "            roi_layer=dict(type='RoIAlign', output_size=14, sampling_ratio=0),\r\n",
        "            out_channels=256,\r\n",
        "            featmap_strides=[4, 8, 16, 32]),\r\n",
        "        mask_head=dict(\r\n",
        "            type='FCNMaskHead',\r\n",
        "            num_convs=4,\r\n",
        "            in_channels=256,\r\n",
        "            conv_out_channels=256,\r\n",
        "            num_classes=4,\r\n",
        "            loss_mask=dict(\r\n",
        "                type='CrossEntropyLoss', use_mask=True, loss_weight=1.0))),\r\n",
        "    # model training and testing settings\r\n",
        "    train_cfg=dict(\r\n",
        "        rpn=dict(\r\n",
        "            assigner=dict(\r\n",
        "                type='MaxIoUAssigner',\r\n",
        "                pos_iou_thr=0.7,\r\n",
        "                neg_iou_thr=0.3,\r\n",
        "                min_pos_iou=0.3,\r\n",
        "                match_low_quality=True,\r\n",
        "                ignore_iof_thr=-1),\r\n",
        "            sampler=dict(\r\n",
        "                type='RandomSampler',\r\n",
        "                num=256,\r\n",
        "                pos_fraction=0.5,\r\n",
        "                neg_pos_ub=-1,\r\n",
        "                add_gt_as_proposals=False),\r\n",
        "            allowed_border=-1,\r\n",
        "            pos_weight=-1,\r\n",
        "            debug=False),\r\n",
        "        rpn_proposal=dict(\r\n",
        "            nms_across_levels=False,\r\n",
        "            nms_pre=2000,\r\n",
        "            nms_post=1000,\r\n",
        "            max_num=1000,\r\n",
        "            nms_thr=0.7,\r\n",
        "            min_bbox_size=0),\r\n",
        "        rcnn=dict(\r\n",
        "            assigner=dict(\r\n",
        "                type='MaxIoUAssigner',\r\n",
        "                pos_iou_thr=0.5,\r\n",
        "                neg_iou_thr=0.5,\r\n",
        "                min_pos_iou=0.5,\r\n",
        "                match_low_quality=True,\r\n",
        "                ignore_iof_thr=-1),\r\n",
        "            sampler=dict(\r\n",
        "                type='RandomSampler',\r\n",
        "                num=512,\r\n",
        "                pos_fraction=0.25,\r\n",
        "                neg_pos_ub=-1,\r\n",
        "                add_gt_as_proposals=True),\r\n",
        "            mask_size=28,\r\n",
        "            pos_weight=-1,\r\n",
        "            debug=False)),\r\n",
        "    test_cfg=dict(\r\n",
        "        rpn=dict(\r\n",
        "            nms_across_levels=False,\r\n",
        "            nms_pre=1000,\r\n",
        "            nms_post=1000,\r\n",
        "            max_num=1000,\r\n",
        "            nms_thr=0.7,\r\n",
        "            min_bbox_size=0),\r\n",
        "        rcnn=dict(\r\n",
        "            score_thr=0.05,\r\n",
        "            nms=dict(type='nms', iou_threshold=0.5),\r\n",
        "            max_per_img=100,\r\n",
        "            mask_thr_binary=0.5)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "zl8PeWHRtZuI"
      },
      "source": [
        "#@title coco_instance.py (config paths)\r\n",
        "%%writefile /content/mmdetection/configs/_base_/datasets/coco_instance.py \r\n",
        "dataset_type = 'CocoDataset'\r\n",
        "data_root = 'data/coco/'\r\n",
        "img_norm_cfg = dict(\r\n",
        "    mean=[123.675, 116.28, 103.53], std=[58.395, 57.12, 57.375], to_rgb=True)\r\n",
        "train_pipeline = [\r\n",
        "    dict(type='LoadImageFromFile'),\r\n",
        "    dict(type='LoadAnnotations', with_bbox=True, with_mask=True),\r\n",
        "    dict(type='Resize', img_scale=(1333, 800), keep_ratio=True),\r\n",
        "    dict(type='RandomFlip', flip_ratio=0.5),\r\n",
        "    dict(type='Normalize', **img_norm_cfg),\r\n",
        "    dict(type='Pad', size_divisor=32),\r\n",
        "    dict(type='DefaultFormatBundle'),\r\n",
        "    dict(type='Collect', keys=['img', 'gt_bboxes', 'gt_labels', 'gt_masks']),\r\n",
        "]\r\n",
        "test_pipeline = [\r\n",
        "    dict(type='LoadImageFromFile'),\r\n",
        "    dict(\r\n",
        "        type='MultiScaleFlipAug',\r\n",
        "        img_scale=(1333, 800),\r\n",
        "        flip=False,\r\n",
        "        transforms=[\r\n",
        "            dict(type='Resize', keep_ratio=True),\r\n",
        "            dict(type='RandomFlip'),\r\n",
        "            dict(type='Normalize', **img_norm_cfg),\r\n",
        "            dict(type='Pad', size_divisor=32),\r\n",
        "            dict(type='ImageToTensor', keys=['img']),\r\n",
        "            dict(type='Collect', keys=['img']),\r\n",
        "        ])\r\n",
        "]\r\n",
        "data = dict(\r\n",
        "    samples_per_gpu=2,\r\n",
        "    workers_per_gpu=2,\r\n",
        "    train=dict(\r\n",
        "        type=dataset_type,\r\n",
        "        ann_file='/content/object_detection/images/train.json',\r\n",
        "        img_prefix='/content/object_detection/images/train/',\r\n",
        "        pipeline=train_pipeline),\r\n",
        "    val=dict(\r\n",
        "        type=dataset_type,\r\n",
        "        ann_file='/content/object_detection/images/test.json',\r\n",
        "        img_prefix='/content/object_detection/images/test/',\r\n",
        "        pipeline=test_pipeline),\r\n",
        "    test=dict(\r\n",
        "        type=dataset_type,\r\n",
        "        ann_file='/content/object_detection/images/test.json',\r\n",
        "        img_prefix='/content/object_detection/images/test',\r\n",
        "        pipeline=test_pipeline))\r\n",
        "evaluation = dict(metric=['bbox', 'segm'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80YS443TrIpG"
      },
      "source": [
        "[TannerGilbert/Tensorflow-Object-Detection-API-train-custom-Mask-R-CNN-model](https://github.com/TannerGilbert/Tensorflow-Object-Detection-API-train-custom-Mask-R-CNN-model) contains a small coco dataset, which is used as a test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vBWg1M3wrJ4z"
      },
      "source": [
        "%cd /content/\r\n",
        "!git clone https://github.com/TannerGilbert/Tensorflow-Object-Detection-API-train-custom-Mask-R-CNN-model object_detection"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHgPqcFRnwP9"
      },
      "source": [
        "#https://github.com/open-mmlab/mmdetection/issues/3305\r\n",
        "%cd /content/mmdetection\r\n",
        "!python tools/train.py /content/mmdetection/configs/mask_rcnn/mask_rcnn_r50_fpn_2x_coco.py"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agmqKBeK1GOK"
      },
      "source": [
        "# Test\r\n",
        "Models are now in ```/content/mmdetection/work_dirs/mask_rcnn_r50_fpn_2x_coco/``` and can be used. Testing output will be in the same path."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNRy702z3g05"
      },
      "source": [
        "%cd /content/mmdetection\r\n",
        "!python tools/test.py \\\r\n",
        "    /content/mmdetection/configs/mask_rcnn/mask_rcnn_r50_fpn_2x_coco.py \\\r\n",
        "    /content/mmdetection/work_dirs/mask_rcnn_r50_fpn_2x_coco/latest.pth \\\r\n",
        "    --eval \"bbox\" \\\r\n",
        "    --show-dir /content/mmdetection/work_dirs/mask_rcnn_r50_fpn_2x_coco"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "2mdVMfg15SAf"
      },
      "source": [
        "#@title show one example\r\n",
        "from IPython.display import Image\r\n",
        "Image('/content/mmdetection/work_dirs/mask_rcnn_r50_fpn_2x_coco/IMG_20181228_102641.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}